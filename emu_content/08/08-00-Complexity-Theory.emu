|> section
    title_gr 
    title_en Complexity Theory
    number 8.0
    counter DefCtr
    counter ExoCtr
    |> div
        id link-to-toc
        |> a
            href ../vorlesungsskript.html

            Inhaltsverzeichnis
        |> a
            href 07-08-PCP-applications.html

            &lt;&lt; Kapitel 7.8
    |> div
        id link-to-overview
        style text-align: end
        |> a
            href /

            zur Kursübersicht
        |> a
            href 08-01-Time-hierarchy-theorem.html

            Kapitel 8.1 &gt;&gt;
    |> div
        id rightSideWrapper
        |> div
            class content
            |> div
                class chapter
                |> div
                    class subChapter
                    |> h1
                        class hidden-title
                        |> span
                            class chapterTitle

                            ::++ChapterCtr.
                            Komplexitätstheorie
                    |> p

                        Turingmaschinen erlauben uns, den Resourcenverbrauch einer Berechnung zu quantifizieren:
                        zum einen die _Zeit_, also die Anzahl der Schritte, die die Turingmaschine
                        durchführt, bis sie anhält; zum anderen der _Speicherplatz_, also die Anzahl
                        der Zellen auf dem Band (oder den Bändern), die im Verlauf der Berechnung beschrieben werden.
                        Beides sind Maße, die tatsächlich im echten Leben relevant sind. Turingmaschinen erlauben uns,
                        diese genau zu quantifizieren und die Zeitkomplexität und Speicherkomplexität eines Problems
                        zu untersuchen. In diesem Kapitel werden wir uns zum Großteil auf Zeitkomplexität beschränken.
                    |> p

                        Es gibt weitere Resourcen, die man mit Turingmaschinen nicht wirklich quantifizieren kann:
                    |> ul
                        |> li

                            *I/O-Komplexität.* In echten Rechnern haben wir eine Hierarchie von
                            Speichermedien. Den extrem schnellen Prozessorcache; schnellen Cache; den vergleichsweise
                            langsamen
                            Hauptstpeicher (RAM); eventuell sogar einen externen Festplattenspeichern, der um
                            Größenordnungen langsamer ist.
                        |> li

                            *Kommunikationskomplexität.* Bei verteilten Anwendungen (Cloud Computing) ist
                            die limitierende Resource eventuell gar nicht die Rechenkapazität sondern das_Netzwerk_, über
                            das die Daten ausgetauscht werden.
                    |> p

                        Also: Turingmaschinen sind zwar universell in dem Sinne, dass sie wohl alle physikalisch
                        realisierbaren
                        Rechnermodelle simulieren können (ich sage _wohl_, weil wir nicht wissen, was alles
                        physikalisch realisierbar ist). Allerdings ist es möglich, dass Sie, abhängig von Ihrem
                        Anwendungsfeld, ein abgewandeltes oder völlig anderes Modell benötigen, um den
                        Resourcenverbrauch modellieren zu können.
                    |> p

                        Dennoch: in diesem Kapitel beschränken wir uns auf die Resource _Zeit_, und daher
                        sind Turingmaschinen das Modell der Wahl.
                    |> h2

                        Zeitkomplexitätsklassen
                    |> p

                        Wir beschränken uns der Einfachheit halber auf das Eingabealphabet $\Sigma = \{0,1\}$ und
                        auf Entscheidungsprobleme, wo uns also nur eine Ja/Nein-Antwort interessiert.
                    |> div
                        class well container theorem
                        |> p
                            |> span
                                class numbered-title

                                Definition
                                |> NumberedTitle

                                    ::::ChapterCtr.::::SectionCtr.::++DefCtr
                            &ensp;Sei $t: \N \rightarrow \N$. Eine
                            Turingmaschinen $M$_entscheidet_ eine Sprache $L \subseteq \Sigma^*$ in Zeit $t$ wenn
                        |> ul
                            |> li

                                sie die Sprache entscheidet, also $x \in L \Longleftrightarrow f_M(x) = \texttt{accept}$
                                und
                            |> li

                                für jede Eingabe $x$ in maximal $O(t(|x|))$ Schritten terminiert.
                        |> p

                            Wir definieren nun
                        \begin{align*}
                        \TIME_k(t) := \{L \subseteq \Sigma^* \ | \
                        \textnormal{es gibt eine $k$-Band-TM $M$, die $L$ in Zeit $t$ entscheidet}\}
                        \end{align*}
                        |> p

                            und schließlich
                        \begin{align*}
                        \TIME(t) := \bigcup_{k \geq 1} \TIME_k(t) \ .
                        \end{align*}
                    |> p

                        Falls Sie sich nicht mehr genau an die $O$-Notation erinnern können: in diesem Zusammenhang
                        heißt das, dass es Konstanten $c$ und $d$ gibt, so dass $M$ in maximal
                        $c t(|x|) + d$ Schritten terminiert. Die Konstanten $c$ und $d$ dürfen von $M$ abhängen, aber
                        nicht von der Eingabe $x$ oder der Länge $|x|$.
                        Wir haben in 
                        |> a
                            href 07-02-Turing-variants.html

                            Kapitel 7.3
                        &ensp;gezeigt, wie man eine
                        $k$-Band-Turingmaschine $M$ durch eine
                        Ein-Band-Turingmaschine $M'$. Der Aufwand war quadratisch: wenn $M$ innerhalb von $t$ Schritten
                        terminiert, so terminiert $M'$ innerhalb von $c t^2$ Schritten, wobei $c$ eine Konstante ist,
                        die
                        von $M$ abhängt. Mit unser neuen Notation können wir das sehr konzis schreiben:
                    |> div
                        class well container theorem
                        |> p
                            |> span
                                class numbered-title

                                Theorem
                                |> NumberedTitle

                                    ::::ChapterCtr.::::SectionCtr.::++DefCtr
                            &ensp;*($k$-Band zu $1$-Band).*Sei $t: \N \rightarrow \N$. Dann gilt
                            $\TIME_k(t) \subseteq \TIME_1(t^2)$.
                    |> p

                        Der quadratische Overhead wird tatsächlich störend, wenn man Zeit als Resource untersucht.
                        Daher gibt es eine bessere Simulation; die benötigt allerdings zwei Bänder (Oder drei? Weiß ich
                        gerade nicht
                        exakt) und die Konstruktion ist deutlich komplizierter. Daher vorerst ohne Beweis:
                    |> div
                        id k-tape-to-2-tape
                        class well container theorem
                        |> p
                            |> span
                                class numbered-title

                                Theorem
                                |> NumberedTitle

                                    ::::ChapterCtr.::::SectionCtr.::++DefCtr
                            &ensp;*($k$-Band zu $2$-Band; ohne
                            Beweis).* Sei
                            $t: \N \rightarrow \N$. Dann gilt $\TIME_k(t) \subseteq \TIME_2(t \log t)$.